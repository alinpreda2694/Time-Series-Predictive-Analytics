{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "def listing_preprocessing(root_folder, city_area):\n",
    "    ######################################################################################################\n",
    "    import time\n",
    "\n",
    "    # Runtime starting time\n",
    "    start_time = time.time()\n",
    "\n",
    "    import pandas as pd \n",
    "    import numpy as np\n",
    "    import os \n",
    "    from datetime import datetime as dt\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    root = root_folder\n",
    "    #os.chdir(root)\n",
    "    df = pd.read_csv(root, low_memory=False)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def pandas_display_options(rows, columns, width):\n",
    "        '''\n",
    "        This function is suited for EDA. It allows you to display samples of big dataframes in iPython.\n",
    "        '''\n",
    "        pd.set_option('display.max_rows', rows)\n",
    "        pd.set_option('display.max_columns', columns) # So we can display all columns\n",
    "        pd.set_option('display.width', width)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def dtype_groups(df):\n",
    "        '''\n",
    "        A very elegant way of displaying the features, grouped by their data types.\n",
    "        '''\n",
    "        return (df.columns.to_series().groupby(df.dtypes).groups)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def amenities_counter(amenities):\n",
    "        '''\n",
    "        Counts the number of amenities. I don't think they're that great.\n",
    "        To run this function, try: df[\"amenities_counter\"] = df.amenities.map(amenities_counter)\n",
    "        '''\n",
    "        return len(amenities.split(\",\"))\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def top_ammenities(df, top =None, plot = False):\n",
    "        '''\n",
    "        This function takes apart that horrible looking dictionary and returns for us the x most common/uncommon ammenities.\n",
    "        It can also plot them if you like.\n",
    "        '''\n",
    "        from collections import Counter\n",
    "        results = Counter()\n",
    "        df['amenities'].str.strip('{}')\\\n",
    "                       .str.replace('\"', '')\\\n",
    "                       .str.lstrip('\\\"')\\\n",
    "                       .str.rstrip('\\\"')\\\n",
    "                       .str.split(',')\\\n",
    "                       .apply(results.update)\n",
    "\n",
    "        if plot == True:\n",
    "            import matplotlib.pyplot as plt\n",
    "            # create a new dataframe\n",
    "            sub_df0 = pd.DataFrame(results.most_common(top), columns=['amenity', 'count'])\n",
    "            # plot the Top \n",
    "            sub_df0.sort_values(by=['count'], ascending=True).plot(kind='barh', x='amenity', y='count',  \n",
    "                                                          figsize=(10,7), legend=False, color='darkgrey',\n",
    "                                                          title='Amenities')\n",
    "            plt.xlabel('Count');\n",
    "\n",
    "\n",
    "        return(results.most_common(top))\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def get_nulls(df):\n",
    "        '''\n",
    "        This function prints out the columns which have or do not have null values and the sum of nulls.\n",
    "        Then, if present, it finally prints out only the names of the columns which are problematic. \n",
    "\n",
    "        Input: A data frame. \n",
    "\n",
    "        '''\n",
    "        columns = df.columns\n",
    "\n",
    "        # Print which columns have nulls or not. \n",
    "        print('\\033[1m')\n",
    "        print(\"Information about which columns have nulls or not:\")\n",
    "        print('\\033[0m')\n",
    "        print(df.isna().any())\n",
    "\n",
    "        # How many nulls in each column?\n",
    "        print('\\033[1m')\n",
    "        print(\"How many null values does each variable hold?\")\n",
    "        print('\\033[0m')\n",
    "        print(df.isna().sum())\n",
    "\n",
    "        # List to store result \n",
    "        problem_columns = []\n",
    "\n",
    "        # Names of columns with problems. \n",
    "        for i in range (0, len(df.isna().sum())):\n",
    "            if df.isna().sum()[i] == 0:\n",
    "                problem_columns.append(columns[i])\n",
    "        if not problem_columns:\n",
    "            print('\\033[1m\\nThere are no variables affected by null values.\\033[0m')\n",
    "        else:\n",
    "            print('\\033[1m\\nThese are the column names of the variables which present problems:\\033[0m')\n",
    "            print(problem_columns)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    ''' MISCELANEOUS '''\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def convert_to_euro(amount,currency):\n",
    "        '''\n",
    "        This converter uses no API at the moment. Just need to update the currency rate list.\n",
    "        You input the amount of currency you want to convert and the currency you convert to.\n",
    "        '''\n",
    "        rates = [(0.13,\"DKK\"),(1.20,\"GBP\"),(1.0,\"EUR\")]\n",
    "\n",
    "        def getall(my_list, s):\n",
    "            index = [x for x, y in my_list if y==s] # Very versatile. \n",
    "            return (index[0])\n",
    "\n",
    "        rate = getall(rates, currency)\n",
    "        out = amount * rate\n",
    "        return (out)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def text_word_len(text):\n",
    "        '''\n",
    "        Returns the length of a text (in number of words used).\n",
    "        This could ascribe some quantifiable value to strings.\n",
    "        '''\n",
    "        return(len(text.split(\" \")))\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def amenities_list_counter(amenities):\n",
    "        '''\n",
    "        Returns the length of an amenities group list.\n",
    "        '''\n",
    "        return len(amenities)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    ''' DATA TYPE CONVERSION '''\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def listings_to_datetime(df, feature):\n",
    "        df[feature] = pd.to_datetime(df[feature])\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def listings_to_float(df, feature):\n",
    "        df[feature] = df[feature].astype(float)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def price_to_float(df, feature):\n",
    "        '''\n",
    "        This function deletes dollar signs from prices and then converts the remaining string to float.\n",
    "        '''\n",
    "        df[feature] = df[feature].replace('[\\$,]', '', regex=True).astype(float)\n",
    "        df[feature] = pd.to_numeric(df[feature])\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def percent_string_to_number(df, feature):\n",
    "        '''\n",
    "        Replaces the string % and then converts the number to a percentage between 0 and 1.\n",
    "        Here, it's host response rate.\n",
    "        '''\n",
    "        df[feature] = df[feature].str.replace('%', '').astype(float)\n",
    "        df[feature] = df[feature] / 100\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def memory_optimization(df, feature):\n",
    "        '''\n",
    "        Transforming features to category instead of obsects saves up a lot of physical memory space.\n",
    "        '''\n",
    "        df[feature] = df[feature].astype('category')\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    ''' NANS, OUTLIERS AND DUPLICATES'''\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def fill_nans(df,feature,filling=\"mean\"):\n",
    "        '''\n",
    "        Fills Nans by replacing them with either median, mean, or a value chosen by the user.\n",
    "        Default filling value is mean.\n",
    "        '''\n",
    "        if filling == \"median\":\n",
    "            median = df[feature].median()\n",
    "            df[feature] = df[feature].fillna(median)\n",
    "        elif filling == \"mean\":\n",
    "            mean = df[feature].mean()\n",
    "            df[feature] = df[feature].fillna(mean)\n",
    "        else:\n",
    "            df[feature].fillna(filling, inplace=True)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def remove_outliers(df,feature, bound = \"both\", method=\"iqr\"):\n",
    "        '''\n",
    "        This function removes outliers in a versatile way, according to needs and preferences.\n",
    "        The method is either Interquartilic Range, Z-Scores or just deleting the dop and bottom 1% values.\n",
    "        Furthermore, you can specify if you want to remove the lower or upper bound outliers. Or both.\n",
    "        '''\n",
    "        if method == \"iqr\":\n",
    "            q1 = df[feature].quantile(0.25)\n",
    "            q3 = df[feature].quantile(0.75)\n",
    "            iqr = q3-q1\n",
    "            lower_bound = q1 - (1.5*iqr)\n",
    "            upper_bound = q3 + (1.5*iqr)\n",
    "\n",
    "            if bound == \"both\":\n",
    "                df.drop(df[ (df[feature] > upper_bound) & (df[feature]) < lower_bound].index, axis=0, inplace=True)\n",
    "            elif bound == \"lower\":\n",
    "                df.drop(df[ df[feature] < lower_bound ].index, axis=0, inplace=True)\n",
    "            elif bound == \"upper\":\n",
    "                df.drop(df[ df[feature] > upper_bound ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif method == \"zscore\":\n",
    "            from scipy import stats\n",
    "            df.drop(df[ np.abs(stats.zscore(df[feature]) < 3)], axis=0, inplace=True)\n",
    "\n",
    "        elif method == \"1%\":\n",
    "            qhigh = df[feature].quantile(0.99)\n",
    "            qlow = df[feature].quantile(0.01)\n",
    "\n",
    "            if bound == \"both\":\n",
    "                df.drop(df[ (df[feature] > qhigh) & (df[feature] < qlow) ].index, axis=0, inplace=True)\n",
    "            elif bound == \"lower\":\n",
    "                df.drop(df[ df[feature] < qlow ].index, axis=0, inplace=True)\n",
    "            elif bound == \"upper\":\n",
    "                df.drop(df[ df[feature] > qhigh ].index, axis=0, inplace=True)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def delete_rows_conditional(df, condition1, threshold1, feature1,\n",
    "                    condition2 = None, threshold2 = None, feature2 = None, \n",
    "                    logical_operator = None):\n",
    "        '''\n",
    "\n",
    "        This function deletes rows based on certain features, conditions and thresholds. \n",
    "        The features and conditions are not unique and can repeat themselves.\n",
    "        The logical operator parameter dictates the relationship between the two conditions.\n",
    "\n",
    "        The following parameters can take only the following values:\n",
    "            - condition = ['greater_than', 'lesser_than', 'equal_to', 'not_equal_to']\n",
    "            - logical_operator = ['and', 'or']\n",
    "\n",
    "        '''\n",
    "        ########### 1) ONE CONDITION CASE ##########\n",
    "        if condition2 == None:\n",
    "\n",
    "            if condition1 == 'greater_than':\n",
    "                df.drop(df[ (df[feature1] > threshold1) ].index, axis=0, inplace=True)\n",
    "\n",
    "            elif condition1 == 'lesser_than':\n",
    "                df.drop(df[ (df[feature1] < threshold1) ].index, axis=0, inplace=True)\n",
    "\n",
    "            elif condition1 == 'equal_to':\n",
    "                df.drop(df[ (df[feature1] == threshold1) ].index, axis=0, inplace=True)\n",
    "\n",
    "            elif condition1 == 'not_equal_to':\n",
    "                df.drop(df[ (df[feature1] != threshold1) ].index, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "        ########### 2) TWO CONDITIONS CASE ##########\n",
    "\n",
    "        #################################################################################################################\n",
    "        elif condition1 == 'greater_than' and condition2 == 'greater_than' and condition3 == None:\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] > threshold1) and (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] > threshold1) | (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'greater_than' and condition2 == 'lesser_than' and condition3 == None:\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] > threshold1) and (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] > threshold1) | (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'lesser_than' and condition2 == 'greater_than' and condition3 == None:\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] < threshold1) and (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] < threshold1) | (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'lesser_than' and condition2 == 'lesser_than':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] < threshold1) and (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] < threshold1) | (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        #################################################################################################################        \n",
    "\n",
    "        elif condition1 == 'equal_to' and condition2 == 'equal_to':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] == threshold1) and (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] == threshold1) | (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'not_equal_to' and condition2 == 'not_equal_to':\n",
    "\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] != threshold1) and (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] != threshold1) | (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'equal_to' and condition2 == 'not_equal_to':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] == threshold1) and (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] == threshold1) | (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'not_equal_to' and condition2 == 'equal_to':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] != threshold1) and (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] != threshold1) | (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        #################################################################################################################\n",
    "\n",
    "        elif condition1 == 'greater_than' and condition2 == 'equal_to':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] != threshold1) and (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] != threshold1) | (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'greater_than' and condition2 == 'not_equal_to':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] > threshold1) and (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] > threshold1) | (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'equal_to' and condition2 == 'greater_than':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] == threshold1) and (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] == threshold1) | (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'not_equal_to' and condition2 == 'greater_than':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] != threshold1) and (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] != threshold1) | (df[feature2] > threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'lesser_than' and condition2 == 'equal_to':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] < threshold1) and (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] < threshold1) | (df[feature2] == threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'lesser_than' and condition2 == 'not_equal_to':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] < threshold1) and (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] < threshold1) | (df[feature2] != threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'equal_to' and condition2 == 'lesser_than':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] == threshold1) and (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] == threshold1) | (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        elif condition1 == 'not_equal_to' and condition2 == 'lesser_than':\n",
    "            if logical_operator == 'and':\n",
    "                df.drop(df[ (df[feature1] != threshold1) and (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "            elif logical_operator == 'or':\n",
    "                df.drop(df[ (df[feature1] != threshold1) | (df[feature2] < threshold2) ].index, axis=0, inplace=True)\n",
    "\n",
    "        else:\n",
    "            print(\"Exception: An error has occured. Please refer to the function's docstring and make sure you specify the parameters correctly.\")\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    ''' FEATURE ENCODING '''\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def make_dummy(df, feature):\n",
    "        dummy = pd.get_dummies(df[feature])\n",
    "        return(dummy)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def encode_label(df, feature):\n",
    "        '''\n",
    "        Just the Sklearn LabelEncoder but made easier to implement.\n",
    "        Obs: It's usually preferable to just one-hot encode the data. \n",
    "        Label encoding makes the machine think the numbers have some kind of ordinal meaning.\n",
    "        '''\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        labelencoder = LabelEncoder()\n",
    "        df[feature] = labelencoder.fit_transform(df[feature])\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def map_feature(df, feature):\n",
    "        '''\n",
    "        Just encodes f(false) as 0 and t(true) as 1. \n",
    "        '''\n",
    "        df[feature] = df[feature].map({\"f\": 0, \"t\": 1})\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    ''' NORMALIZATION '''\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def normalize_price(df,feature,method=\"standard score\"):\n",
    "        '''\n",
    "        In statistics, the standard score is the signed fractional number of standard \n",
    "        deviations by which the value of an observation or data point is above or below \n",
    "        the mean value of what is being observed or measured.\n",
    "        '''\n",
    "        # This should get rid of the need to convert currency.\n",
    "        # And, most importantly, we can now concatenate different listings DF for different cities and even times.\n",
    "        if method == \"standard score\":\n",
    "            df[feature] = (df[feature] - df[feature].mean())/df[feature].std()\n",
    "            normalized_df=(df-df.mean())/df.std()\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    ''' FEATURE DELETION '''\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def drop_or_keep_feature(df, threshold, print_option = False):\n",
    "        ''' \n",
    "        This function deletes features that contain more than x% missing values. \n",
    "        Or rather, it returns a tuple containing the names of features to keep and features to drop.\n",
    "        It also prints them out, if desired. Default is false.\n",
    "        Threshold example: 30% is 0.3.\n",
    "        '''\n",
    "        cols = df.columns.values # Names of features\n",
    "        lenght = df.shape[0] \n",
    "        # Initialize lists\n",
    "        keep_list = [] \n",
    "        drop_list = []\n",
    "\n",
    "        for i in cols:\n",
    "            x = df[i]\n",
    "            rate = round(x.isna().sum()/lenght,3)\n",
    "            if rate < threshold:\n",
    "                keep_list.append(i)\n",
    "                if print_option == True:\n",
    "                    print(i,\"contain :%\",100*rate ,\"KEEP.\")\n",
    "            else:\n",
    "                drop_list.append(i)\n",
    "                if print_option == True:\n",
    "                    print(i,\"contain :%\",rate*100 ,\"DROP !!!\")\n",
    "\n",
    "        return(keep_list, drop_list)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    ''' FEATURE ENGINEERING '''\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def city_center(city=df[\"city\"].iloc[0]):\n",
    "        from geopy import Nominatim\n",
    "        locator = Nominatim(user_agent=\"aleen_prd\")\n",
    "        location = locator.geocode(city, timeout=5)\n",
    "        center = (location.latitude, location.longitude)\n",
    "        return(center)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def distance_to_center(acc_lat, acc_lon, center, city_area):\n",
    "        '''\n",
    "        Uses an API to calculate the distance in km to the city center of an Airbnb location.\n",
    "        '''\n",
    "        from geopy.distance import great_circle\n",
    "        accommodation = (acc_lat, acc_lon)\n",
    "        distance = great_circle(center, accommodation).km\n",
    "        return (distance/city_area)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def host_age(df, present_year):\n",
    "        df['host_age'] = (present_year - df['host_since'].dt.year)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def assign_property_type_group():\n",
    "        groups_list = [\"apartment\",\"house\",\"secondary\",\"unique\",\"b&b\",\"hotel\",\"ambiguous\"]\n",
    "        groups_lis_list = [apartmentL,houseL,secondaryL,uniqueL,bedbreakfastL,hotelL,ambiguousL]\n",
    "\n",
    "        for g in range(len(groups_list)):\n",
    "            df.loc[df['property_type'].isin(groups_lis_list[g]), 'property_type_groups'] = groups_list[g]\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    def common(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in commonL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def additional(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in additionalL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def family(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in familyL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def logistics(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in logisticsL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def homesafety(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in homesafetyL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def location(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in locationL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def pets(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in petsL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def access(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in accessL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def specialneeds(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in specialneedsL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def spacious(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity in spaciousL:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "    def other(row):\n",
    "        out = []\n",
    "        for amenity in row['amenities']:\n",
    "            if amenity not in all_amenities:\n",
    "                out.append(amenity)\n",
    "        return(out)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    # Setting up optimal display for a dataframe with so many features.\n",
    "    pandas_display_options(3,150,150)\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    commonL = ['Essentials','Kitchen','Air conditioning','Heating','Hair dryer','Hangers','Iron','Washer','Dryer','Hot water',\n",
    "              'TV','Cable TV','Indoor fireplace','Private entrance','Private living room','Lock on bedroom door','Shampoo',\n",
    "              'Shower gel','Bed linens','Extra pillows and blankets','Wifi','Ethernet connection','Pocket wifi','Laptop-friendly workspace',\n",
    "              'Internet','Laptop friendly workspace','Washer / Dryer',' toilet']\n",
    "\n",
    "    additionalL = ['Microwave','Coffee maker','Refrigerator','Dishwasher','Dishes and silverware','Cooking basics','Oven','Stove',\n",
    "                  'Bread maker','Baking sheet','Barbeque utensils','Trash can','Free parking on premises','Free street parking',\n",
    "                  'Paid parking off premises','Paid parking on premises','EV charger','Gym','Pool','Hot tub','Single level home',\n",
    "                  'BBQ grill','Patio or balcony','Garden or backyard','Breakfast','Beach essentials',\n",
    "                  'Handheld shower head','Lockbox','Hot water kettle','Firm mattress']\n",
    "\n",
    "    familyL = ['Baby bath','Baby monitor','Babysitter recommendations','Bathtub','Changing table',\"Children's books and toys\",\"Children's dinnerware\",\n",
    "              'Crib','Fireplace guards','Game console','High chair','Outlet covers',\"Pack'n Play/travel crib\",'Room-darkening shades',\n",
    "              'Stair gates','Table corner guards','Window guards',\n",
    "              'Family/kid friendly','Pack ’n Play/travel crib','Children’s books and toys','Children’s dinnerware']\n",
    "\n",
    "    logisticsL = ['Luggage dropoff allowed','Cleaning before checkout','Long term stays allowed',\n",
    "                 'Host greets you','24-hour check-in','Self check-in','Smoking allowed','Suitable for events']\n",
    "\n",
    "    homesafetyL = ['Fire extinguisher','Carbon monoxide alarm','Smoke alarm','First aid kit',\n",
    "                  'Smoke detector','Carbon monoxide detector','Accessible-height bed','Safety card',\n",
    "                  'Accessible-height toilet',]\n",
    "\n",
    "    locationL = ['Beachfront','Lake access','Ski-in/Ski-out','Waterfront']\n",
    "\n",
    "    petsL = ['Pets allowed','Cat(s)','Dog(s)','Pets live on this property']\n",
    "\n",
    "    accessL = ['Buzzer/wireless intercom','Smart lock','No stairs or steps to enter','Elevator','Well-lit path to entrance',\n",
    "              'Buzzer/wireless intercom','Ground floor access','Flat path to guest entrance','Doorman',\n",
    "              'Keypad']\n",
    "\n",
    "    specialneedsL = ['Step-free shower','Electric profiling bed','Wheelchair accessible','Disabled parking spot','Building staff']\n",
    "\n",
    "    spaciousL = ['Wide entrance for guests','Wide hallways','Wide entrance','Wide entryway','Extra space around bed',\n",
    "                'Wide doorway to guest bathroom','Wide clearance to shower']\n",
    "\n",
    "    all_amenities = commonL + additionalL + familyL + logisticsL + homesafetyL + locationL + petsL + accessL + specialneedsL + spaciousL\n",
    "\n",
    "    #####################################################################################################\n",
    "\n",
    "    apartmentL = ['Apartment', 'Condominium', 'Loft']\n",
    "\n",
    "    houseL = ['House', 'Bungalow', 'Cabin', 'Chalet, Cottage', 'Cycladic house (Greece)', \n",
    "             'Dammuso (Italy)', 'Dome house', 'Lighthouse', 'Townhouse', 'Trullo (Italy)']\n",
    "\n",
    "    secondaryL = ['Guesthouse', 'Guest suite']\n",
    "\n",
    "    uniqueL = ['Barn', 'Boat', 'Bus', 'Camper/RV', 'Campsite', 'Castle', 'Cave', 'Dome house',\n",
    "              'Igloo', 'Island', 'Lighthouse', 'Plane', 'Tent', 'Tipi', 'Train', 'Treehouse', 'Windmill', 'Yurt']\n",
    "\n",
    "    bedbreakfastL = ['Bed and breakfast', 'Minsu (Taiwan)','Ryokan (Japan)']\n",
    "\n",
    "    hotelL = ['Boutique hotel', 'Aparthotel', 'Heritage hotel (India)', 'Hostel', 'Hotel',\n",
    "             'Resort', 'Kezhan (China)']\n",
    "\n",
    "    ambiguousL = ['Casa particular (Cuba)', 'Serviced apartment', 'Pension (South Korea)','Tiny house',\"Shepherd's hut (U.K.,France)\",\n",
    "            'Houseboat','Hut','Farm stay','Earth house']\n",
    "\n",
    "    all_listing_types = apartmentL + houseL + secondaryL + uniqueL + bedbreakfastL + hotelL + ambiguousL\n",
    "\n",
    "    #####################################################################################################\n",
    "\n",
    "    df[\"amenities\"] = df[\"amenities\"].apply(lambda x: x.replace('\"', ''))\n",
    "    df[\"amenities\"] = df[\"amenities\"].apply(lambda x: x[1:-1].replace(\"\\'\", \"\").split(\",\"))\n",
    "\n",
    "    #####################################################################################################\n",
    "\n",
    "    df['amenities_common'] = df.apply(common, axis=1)\n",
    "    df['amenities_additional'] = df.apply(additional, axis=1)\n",
    "    df['amenities_family'] = df.apply(family, axis=1)\n",
    "    df['amenities_logistics'] = df.apply(logistics, axis=1)\n",
    "    df['amenities_safety'] = df.apply(homesafety, axis=1)\n",
    "    df['amenities_location'] = df.apply(location, axis=1)\n",
    "    df['amenities_pets'] = df.apply(pets, axis=1)\n",
    "    df['amenities_access'] = df.apply(access, axis=1)\n",
    "    df['amenities_special_needs'] = df.apply(specialneeds, axis=1)\n",
    "    df['amenities_spacious'] = df.apply(spacious, axis=1)\n",
    "    df['amenities_other'] = df.apply(other, axis=1)\n",
    "\n",
    "    #####################################################################################################\n",
    "\n",
    "    df['amenities_common'] = df['amenities_common'].map(amenities_list_counter)\n",
    "    df['amenities_additional'] = df['amenities_additional'].map(amenities_list_counter)\n",
    "    df['amenities_family'] = df['amenities_family'].map(amenities_list_counter)\n",
    "    df['amenities_logistics'] = df['amenities_logistics'].map(amenities_list_counter)\n",
    "    df['amenities_safety'] = df['amenities_safety'].map(amenities_list_counter)\n",
    "    df['amenities_location'] = df['amenities_location'].map(amenities_list_counter)\n",
    "    df['amenities_pets'] = df['amenities_pets'].map(amenities_list_counter)\n",
    "    df['amenities_access'] = df['amenities_access'].map(amenities_list_counter)\n",
    "    df['amenities_special_needs'] = df['amenities_special_needs'].map(amenities_list_counter)\n",
    "    df['amenities_spacious'] = df['amenities_spacious'].map(amenities_list_counter)\n",
    "    print(\"Amenities done.\")\n",
    "    #####################################################################################################\n",
    "\n",
    "    assign_property_type_group()\n",
    "    fill_nans(df,\"property_type_groups\",\"other\")\n",
    "    dummy = make_dummy(df,\"property_type_groups\")\n",
    "    df = df.join(dummy)\n",
    "    print(\"Property type done.\")\n",
    "    #####################################################################################################\n",
    "\n",
    "    center = city_center()\n",
    "    #city_area = 219.32\n",
    "    df['distance_to_center'] = df.apply(lambda x: distance_to_center(x.latitude, x.longitude, center, city_area), axis=1)\n",
    "    print(\"Distance done.\")\n",
    "\n",
    "    #####################################################################################################\n",
    "    ######################################################################################################\n",
    "\n",
    "    to_datetime_list = ['host_since'] # \"last_scraped\"\n",
    "    for f in to_datetime_list:\n",
    "        listings_to_datetime(df, f)\n",
    "\n",
    "    price_to_num_list = ['price','security_deposit','cleaning_fee','extra_people','weekly_price','monthly_price']\n",
    "    for f in price_to_num_list:\n",
    "        price_to_float(df,f)\n",
    "\n",
    "    percent_string_to_number(df, 'host_response_rate')\n",
    "\n",
    "    print(\"Dates, percentages and prices done.\")\n",
    "    #####################################################################################################\n",
    "\n",
    "    host_age(df,2020)\n",
    "    print(\"Host age done.\")\n",
    "    #####################################################################################################\n",
    "\n",
    "    text_features_list = ['name', 'space', 'description', 'experiences_offered', 'neighborhood_overview', 'notes',\n",
    "                            'transit', 'access', 'interaction', 'house_rules', 'host_about']\n",
    "\n",
    "    for f in text_features_list:\n",
    "        fill_nans(df,f,\"\")\n",
    "\n",
    "    for f in text_features_list:\n",
    "        df[f] = df[f].str.split().str.len()\n",
    "    print(\"Text length done.\")\n",
    "    df['summary_text'] = df['summary']\n",
    "    df['summary'] = df['summary'].str.split().str.len()\n",
    "\n",
    "    #####################################################################################################\n",
    "    #####################################################################################################\n",
    "\n",
    "    filling = [0.0, 1.0, \"f\", \"t\",'no_response',\"no bed\", \"no bathroom\",\"median\", \"mean\"]\n",
    "\n",
    "    # Filling NaN with zeros\n",
    "    fillna_zeros_features_list = [\"price\",'weekly_price','monthly_price',\"extra_people\",\"cleaning_fee\",\n",
    "                                  \"security_deposit\",\"bathrooms\",\"bedrooms\",\"beds\",\n",
    "                                  \"review_scores_rating\",\"review_scores_accuracy\"]\n",
    "    for f in fillna_zeros_features_list:\n",
    "        fill_nans(df,f,filling[0])\n",
    "\n",
    "    # Filling NaN with f\n",
    "    fillna_features_list = [\"host_is_superhost\",\"instant_bookable\",\"is_business_travel_ready\", \"host_identity_verified\",\n",
    "                            \"require_guest_profile_picture\",\"require_guest_phone_verification\"]\n",
    "    for f in fillna_features_list:\n",
    "        fill_nans(df,f,filling[2])\n",
    "\n",
    "    # Filling NaN with \"no response\"\n",
    "        fill_nans(df,\"host_response_time\",filling[4])\n",
    "\n",
    "    # Filling NaN with \"no bed\"\n",
    "    fill_nans(df,\"bed_type\",filling[5])\n",
    "\n",
    "    # Filling NaN with mean\n",
    "    fill_nans(df,'price',filling[8])\n",
    "    print(\"Filling NaNs done.\")\n",
    "\n",
    "    fill_nans(df,'host_age',0)\n",
    "    fill_nans(df,'reviews_per_month',0)\n",
    "    fill_nans(df,'host_total_listings_count',1)\n",
    "    fill_nans(df,'host_response_rate',0)\n",
    "\n",
    "    #####################################################################################################\n",
    "    #####################################################################################################\n",
    "\n",
    "    features_with_outliers_list_0 = [\"price\"]\n",
    "    for f in features_with_outliers_list_0:\n",
    "        remove_outliers(df, f, bound = \"upper\", method = \"iqr\")\n",
    "\n",
    "    features_with_outliers_list_1 = [\"cleaning_fee\",\"security_deposit\",\"extra_people\",\n",
    "                                     \"accommodates\",\"bathrooms\",\"bedrooms\",\"beds\",\n",
    "                                     \"host_total_listings_count\"]\n",
    "    for f in features_with_outliers_list_1:\n",
    "        remove_outliers(df, f, bound = \"upper\", method = \"iqr\")\n",
    "\n",
    "    delete_rows_conditional(df, feature1='maximum_nights', condition1='greater_than', threshold1=1125)\n",
    "    delete_rows_conditional(df, feature1='accommodates', condition1='equal_to', threshold1=0)\n",
    "    delete_rows_conditional(df, feature1='price', condition1='equal_to', threshold1=0)\n",
    "    print(\"Outliers statistically removed done.\")\n",
    "    #####################################################################################################\n",
    "\n",
    "    label_encoding_list = [\"host_identity_verified\",\"host_has_profile_pic\",\"instant_bookable\",\n",
    "                          \"host_is_superhost\",\"is_business_travel_ready\",\n",
    "                           \"require_guest_profile_picture\",\"require_guest_phone_verification\"]\n",
    "    for f in label_encoding_list:\n",
    "        map_feature(df,f)\n",
    "    print(\"Labels encoded done.\") \n",
    "    #####################################################################################################\n",
    "\n",
    "    dummy_feature_list = [\"host_response_time\",\"cancellation_policy\",\n",
    "                         \"room_type\",\"bed_type\"] \n",
    "    # \"host_verifications\"\n",
    "    for f in dummy_feature_list:\n",
    "        dumm = make_dummy(df,f)\n",
    "        df = pd.concat([df,dumm], axis=1)\n",
    "    print(\"Makind dummies done.\")\n",
    "    #####################################################################################################\n",
    "    #\n",
    "    drop_list = ['thumbnail_url',\n",
    "     'medium_url',\n",
    "     'xl_picture_url',\n",
    "     'host_name',\n",
    "     'host_since',\n",
    "     'host_location',\n",
    "     'host_acceptance_rate',\n",
    "     'host_thumbnail_url',\n",
    "     'host_picture_url',\n",
    "     'host_neighbourhood',\n",
    "     'host_listings_count',\n",
    "     'host_has_profile_pic',\n",
    "     'neighbourhood',\n",
    "     'neighbourhood_group_cleansed',\n",
    "     'state',\n",
    "     'zipcode',\n",
    "     'market',\n",
    "     'square_feet',\n",
    "     'first_review',\n",
    "     'last_review',\n",
    "     'review_scores_cleanliness',\n",
    "     'review_scores_checkin',\n",
    "     'review_scores_communication',\n",
    "     'review_scores_location',\n",
    "     'review_scores_value',\n",
    "     'license',\n",
    "     'jurisdiction_names']\n",
    "    #####################################################################################################\n",
    "\n",
    "    df.drop(drop_list, axis=1,inplace=True)\n",
    "    df.drop(['amenities','amenities_other'], axis=1,inplace=True)\n",
    "    df.drop([\"property_type\",\"property_type_groups\"], axis=1,inplace=True)\n",
    "\n",
    "    additional_drop_list = [\"scrape_id\",\"last_scraped\",\"name\",\"picture_url\",\"host_id\",\"host_url\",\n",
    "                           \"host_verifications\",\"street\",\"neighbourhood_cleansed\",\"city\",\"smart_location\",\"country_code\",\n",
    "                           \"country\",\"latitude\",\"longitude\",\"is_location_exact\",\"room_type\",\"bed_type\",\n",
    "                           \"minimum_minimum_nights\",\"maximum_minimum_nights\",\"minimum_maximum_nights\",\n",
    "                            \"maximum_maximum_nights\",\"minimum_nights_avg_ntm\",\"maximum_nights_avg_ntm\",\"calendar_updated\",\"calendar_last_scraped\",\n",
    "                            \"has_availability\",\"availability_30\",\"availability_60\",\"availability_90\",\"availability_365\",\n",
    "                            \"number_of_reviews_ltm\",\"requires_license\",\n",
    "                            \"host_identity_verified\",\"experiences_offered\",\n",
    "                            \"host_response_time\",\"cancellation_policy\",\n",
    "                            #\"listing_url\",\"id\"\n",
    "                           ]\n",
    "    df.drop(additional_drop_list, axis=1,inplace=True)\n",
    "    print(\"Dropped some extra features.\")\n",
    "    #####################################################################################################\n",
    "\n",
    "    #normalization_list = ['price','security_deposit','cleaning_fee','extra_people','weekly_price','monthly_price']\n",
    "    #for n in normalization_list:\n",
    "       # normalize_price(df,n)\n",
    "    #print(\"Normalization done.\")\n",
    "\n",
    "    # Runtime ending time\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Finished in: \", end_time - start_time)\n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (61,62,94) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20025, 106)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "ams = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\amsterdam\\listings\\listings.csv\")\n",
    "ams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  13.160455226898193\n"
     ]
    }
   ],
   "source": [
    "amsterdam = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\amsterdam\\listings\\listings.csv\",219.32)\n",
    "amsterdam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsterdam.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\amsterdam\\amsterdam_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Athens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11396, 106)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ath = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\athens\\athens_listings.csv\")\n",
    "ath.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  7.308902740478516\n"
     ]
    }
   ],
   "source": [
    "athens = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\athens\\athens_listings.csv\",412)\n",
    "athens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athens['security_deposit'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "athens.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\athens\\athens_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Copenhagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (43,61,62,94) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28418, 106)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cop = ber = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\copenhagen\\copenhagen_listings.csv\")\n",
    "cop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  16.681175470352173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12325, 78)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copenhagen = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\copenhagen\\copenhagen_listings.csv\",292.5)\n",
    "copenhagen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "copenhagen.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\copenhagen\\copenhagen_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copenhagen['security_deposit'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diff(li1, li2): \n",
    "    return (list(set(li1) - set(li2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['super_strict_30']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Diff(list(athens.columns.values),list(copenhagen.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Berlin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (43,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25197, 106)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\berlin\\berlin_listings.csv\")\n",
    "ber.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  15.47740912437439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9592, 79)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\berlin\\berlin_listings.csv\",891.1)\n",
    "berlin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.0284612176814"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin.security_deposit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\berlin\\berlin_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21845, 106)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\madrid\\madrid_listings.csv\")\n",
    "mad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  13.804437398910522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9204, 80)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madrid = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\madrid\\madrid_listings.csv\",604.3)\n",
    "madrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\madrid\\madrid_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (61,62,94,95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87571, 106)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\london\\london_listings.csv\")\n",
    "lon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  52.11855912208557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30002, 81)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\london\\london_listings.csv\",1737.9)\n",
    "london.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "london.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\london\\london_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (43,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66414, 106)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\paris\\paris_listings.csv\")\n",
    "par.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  40.774916887283325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33203, 80)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paris = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\paris\\paris_listings.csv\",105.4)\n",
    "paris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\paris\\paris_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (43,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31202, 106)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rom = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\rome\\rome_listings.csv\")\n",
    "rom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  19.420282125473022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15264, 80)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rome = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\rome\\rome_listings.csv\",1285)\n",
    "rome.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rome.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\rome\\rome_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14560, 106)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pra = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\prague\\prague_listings.csv\")\n",
    "pra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  9.59473466873169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7052, 80)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prague = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\prague\\prague_listings.csv\",298)\n",
    "prague.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prague.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\prague\\prague_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vienna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13162, 106)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vie = pd.read_csv(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\vienna\\vienna_listings.csv\")\n",
    "vie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities done.\n",
      "Property type done.\n",
      "Distance done.\n",
      "Dates, percentages and prices done.\n",
      "Host age done.\n",
      "Text length done.\n",
      "Filling NaNs done.\n",
      "Outliers statistically removed done.\n",
      "Labels encoded done.\n",
      "Makind dummies done.\n",
      "Dropped some extra features.\n",
      "Finished in:  8.382618427276611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5662, 80)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vienna = listing_preprocessing(r\"C:\\Users\\aleen\\Desktop\\Master Thesis\\Data\\vienna\\vienna_listings.csv\",414.78)\n",
    "vienna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vienna.to_csv(r\"C:\\Users\\aleen\\Desktop\\Reviews\\vienna\\vienna_listings_root.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
